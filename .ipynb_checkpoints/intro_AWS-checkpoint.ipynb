{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<hr style=\"border: 5px solid#0B0B0B;\" />\n",
    "<br>\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "<div align=\"center\">\n",
    "    <img src= \"/content/innovation_engineering.png\" align=\"center\" width=\"30%\">\n",
    "</div>\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "## INTRODUCTION TO AMAZON WEB SERVICES\n",
    "\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "**Author List:** Elias Castro Hernandez\n",
    "\n",
    "**About (TL/DR):** The following collection of notebooks introduces developers and data scientists to \n",
    "cloud computing services offered by Amazon Web Services (AWS). Cloud computing eliminates the need for large quantities of computing technology and on-site data centers and allow users to pay for what they use. As the leading cloud computing platform in both revenue and market share, AWS provides secure and affordable services for its users. \n",
    "\n",
    "\n",
    "**Learning Goal(s):** Learn why AWS is useful and how to use its core services\n",
    "\n",
    "**Target User:** Data scientists and developers\n",
    "\n",
    "**Prerequisite Knowledge:** none\n",
    "\n",
    "**Copyright:** Content curation has been used to expediate the creation of the following learning materials. Credit and copyright belong to the content creators used in facilitating this content. Please support the creators of the resources used by frequenting their sites, and social media."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<hr style=\"border: 2px solid#0B0B0B;\" />\n",
    "\n",
    "#### CONTENTS: CORE AWS SERVICES\n",
    "\n",
    "> #### PART 1: SIMPLE STORAGE SERVICE\n",
    "\n",
    "> #### PART 2: ELASTIC CLOUD COMPUTE\n",
    "\n",
    "> #### PART 3: MACHINE LEARNING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "#### APPENDIX\n",
    "\n",
    "> #### [**ACCESS AWS SERVER**](https://aws.amazon.com/)\n",
    "\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<hr style=\"border: 2px solid#0B0B0B;\" />\n",
    "\n",
    "\n",
    "#### PART 1\n",
    "<br>\n",
    "\n",
    "## **SIMPLE STORAGE SERVICE (S3)**\n",
    "\n",
    "Amazon's storage service, S3 allows users to store and retrieve unlimited amounts of data, storing files of any type.\n",
    "\n",
    "##### **STRUCTURE**\n",
    "Object < Folder < Object\n",
    "Bucket: folders of files \n",
    "Folder: subfolders\n",
    "Object: file you would like to store; may be placed in buckets or folders\n",
    "\n",
    "\n",
    "##### BENEFITS OF S3\n",
    "\n",
    "##### **1. S3 ACCESS POINTS**\n",
    "<img src= \"https://d1.awsstatic.com/re19/Westeros/Diagram_S3_Access_Points.fa88c474dc1073aede962aaf3a6af2d6b02be933.png\" align = center width = 100%>\n",
    "\n",
    "##### **2. HIGHLY SCALABLE & FLEXIBLE**\n",
    "- can decide data lifestyle\n",
    "- can transfer data securely and quickly at Amazon's high speed internal network\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border: 2px solid#0B0B0B;\" />\n",
    "\n",
    "#### PART 2\n",
    "<br>\n",
    "\n",
    "##  **ELASTIC COMPUTE CLOUD (EC2)**\n",
    "\n",
    "\n",
    "With an [**AWS server**](https://aws.amazon.com/) account, we will access the Elastic Cloud Computer Service (EC2), [**Elastic Compute Cloud (EC2)**](https://aws.amazon.com/ec2/). Think of a basic desktop computer. EC2 is pretty much that, without the hardware and can practically function as an unlimited set of physical computers. This service provides scalable computing capacity which allows you to develop and deploy applications quickly and effectively. You can launch as many servers as you need, configure security and networking, and scale changes whenever you would like. \n",
    "\n",
    "For reference, here is Amazon's guide for using EC2:\n",
    "> [**How to Get Started with Amazon EC2**](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/concepts.html#how-to-get-started) <br>\n",
    "\n",
    "##### **LAUNCHING AN EC2 INSTANCE**\n",
    "An EC2 instance is a virtual server that allows you to run applications on AWS infrastructure. Each server functions as \"computer\" would.\n",
    "STEPS (EDIT THIS!):\n",
    "1. Open EC2 in AWS.\n",
    "2. Adjust the necessary settings.\n",
    "3. Create a key pair to log back into the server or be able to SSH into the instance.\n",
    "4. Download the key pair so that you have access to the instance.\n",
    "5. Deploy instance.\n",
    "\n",
    "TROUBLESHOOTING:\n",
    "Connectivity Issues may be a result of\n",
    "1. security group access\n",
    "2. network access\n",
    "3. control list rules\n",
    "4. route tables\n",
    "5. internet gateways\n",
    "\n",
    "The benefit of EC2 over a standard dekstop computer is its autoscaling function and its elastic IP address that belongs to the AWS account instead of a physical hardware. EC2 then utilizes S3 to store Amazon Machine Images (AMIs), which are used to launch EC2 instances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "___\n",
    "\n",
    "#### PART 3\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "## **MACHINE LEARNING**\n",
    "\n",
    "Machine learning is a method of data analysis that uses algorithms to produce models that can analyze large volumes of complex data. It is a subcategory of Artificial Intelligence that trains machines to \"act\" as humans do through pattern recognition of data so that systems may make decisions with minimal human involvement. Self-driving cars, customized Netflix suggestions, and fraud detection are all examples of machine learning at work. Though extremly useful for companies with large amounts of data, a machine learning service is convenient to use because it is expensive to train models, which requires machine learning expertise, sufficeint data, etc.\n",
    "\n",
    "\n",
    "Amazon Web Services, provides a myriad of pre-trained machine learning services. In particular, Amazon SageMaker allows users to quickly build, train and deploy machine learning models.\n",
    "\n",
    "\n",
    "##### SageMaker\n",
    "SageMaker utilizes pre-built Jupyter Notebooks and provides an Autopilot option that users without machine learning experience can navigate.\n",
    "\n",
    "**Process**:\n",
    "<img src= \"https://d1.awsstatic.com/r2018/r/Samurai/SamurAI%20Customer%20Assets/Product-Page-Diagram_SamurAI_How-it-works-2.bc19de267c29570783c4add8bb2286ee584fcfbc.png\" align = center width = 100%>\n",
    "Ways to Build your Machine Learning Model with SageMaker:\n",
    "1. Select one of SageMaker's built-in algorithm\n",
    "2. Write training script in a SageMaker-supported machine learning framework and run it\n",
    "3. Train your own algorithm\n",
    "4. Use an algorithm from AWS Marketplace\n",
    "\n",
    "For more details, refer [**here**](https://docs.aws.amazon.com/sagemaker/latest/dg/build-model.html).\n",
    "\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intialize Vocab tensor objects\n",
    "text = torchtext_data.Field()\n",
    "label = torchtext_data.Field(sequential=False)  # no tokenization since False\n",
    "\n",
    "\n",
    "# get data and split into testing and training --> https://pytorch.org/text/datasets.html#sst\n",
    "train_data, val_data, test_data = datasets.SST.splits(\n",
    "    text,\n",
    "    label,\n",
    "    fine_grained=True,\n",
    "    train_subtrees=True,  #use all subtrees in the training set\n",
    ")\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "for i in trange(len(train_data), ascii=True):\n",
    "    seq = TreebankWordDetokenizer().detokenize(\n",
    "        vars(train_data[i])[\"text\"]\n",
    "    )\n",
    "    seq = discriminator.tokenizer.encode(seq)\n",
    "    if add_eos_token:\n",
    "        seq = [50256] + seq\n",
    "    seq = torch.tensor(seq, device=device, dtype=torch.long)\n",
    "    x.append(seq)\n",
    "    y.append(class2idx[vars(train_data[i])[\"label\"]])\n",
    "train_dataset = Dataset(x, y)\n",
    "\n",
    "test_x = []\n",
    "test_y = []\n",
    "for i in trange(len(test_data), ascii=True):\n",
    "    seq = TreebankWordDetokenizer().detokenize(\n",
    "        vars(test_data[i])[\"text\"]\n",
    "    )\n",
    "    seq = discriminator.tokenizer.encode(seq)\n",
    "    if add_eos_token:\n",
    "        seq = [50256] + seq\n",
    "    seq = torch.tensor(seq, device=device, dtype=torch.long)\n",
    "    test_x.append(seq)\n",
    "    test_y.append(class2idx[vars(test_data[i])[\"label\"]])\n",
    "test_dataset = Dataset(test_x, test_y)\n",
    "\n",
    "discriminator_meta = {\n",
    "    \"class_size\": len(idx2class),\n",
    "    \"embed_size\": discriminator.embed_size,\n",
    "    \"pretrained_model\": pretrained_model,\n",
    "    \"class_vocab\": class2idx,\n",
    "    \"default_class\": 2,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "___\n",
    "\n",
    "### **Install ALTAIR**\n",
    "\n",
    "```bash\n",
    "# in a new terminal\n",
    "pip install altair vega_datasets \n",
    "```\n",
    "\n",
    "OR\n",
    "\n",
    "```python\n",
    "conda install -c conda-forge altair vega_datasets\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "livereveal": {
   "scroll": true
  },
  "rise": {
   "enable_chalkboard": true,
   "height": "90%",
   "width": "100%"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
